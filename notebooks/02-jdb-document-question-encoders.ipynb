{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "\n",
    "from src.dataset import SquadDataset\n",
    "from src.preprocessing import Preprocessing\n",
    "\n",
    "# Clear memory\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook summary\n",
    "\n",
    "In this notebook we'll set up the model architectures required for the first encoders. These encode the words in the documents, and the words in the questions. Both questions and documents are initially encoded by an LSTM:\n",
    "    \n",
    "    d_t = LSTM_enc(d_t−1, x_t^D)\n",
    "    \n",
    "resulting in document encoding matrix\n",
    "\n",
    "    D = [d1, . . ., d_m, d∅] of L x (m+1) dimensions\n",
    "\n",
    "and\n",
    "\n",
    "    q_t = LSTM_enc(q_t−1, x_t^D)\n",
    "    \n",
    "resulting in intermediate question encoding matrix\n",
    "\n",
    "    Q' = [q_1, . . ., q_n, q∅] of L x (n+1) dimensions\n",
    "\n",
    "to which we then apply a nonlinearity\n",
    "\n",
    "    Q = tanh(W^(Q)Q_0 + b(Q)) of L x (n+1) dimensions\n",
    "\n",
    "Let's start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "glove_file_path = \"../data/glove.840B.300d.txt\"\n",
    "squad_file_path = \"../data/train-v1.1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentEncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(DocumentEncoderLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.lstm(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we have a single document encoding matrix for all documents, or an encoding matrix for each document? It seems we have one for each document, where L is the length of the transformed word vectors and m+1 is the number of words in the document plus a sentinel vector. \n",
    "\n",
    "The shape of the input of a neural net is always defined on the level of a single example, as the batch size may vary. The above would suggest that we feed the network word vectors for a whole document. We pass each word vector through the same LSTM and we obtain new, encoded vectors (which incorporate some of their surrounding context).\n",
    "\n",
    "This raises another question: how are we training this encoding? It seems we do not have a target to train on and therefore no error signal, at least in this section on its own. Just feeding the vectors through an LSTM with random weights seems a little pointless. It seems more likely that this is learned by going through the whole architecture. Does this mean that in order to test this we need to have the whole thing set up?\n",
    "\n",
    "After we have both encodings D and Q, we calculate affinity matrix L = (D.transpose Q). This makes it unlikely that the encoders are coupled to the whole network, since it is difficult (impossible?) to disentangle the error signal you backpropagate.\n",
    "\n",
    "SOLUTION: encoders are unsupervised, and they try to learn a mapping from x to x, e.g. they approximate the identity function. So we train the LSTM with backprop and pass our input along as targets. Conceptually, we have the word vectors, which encode meaning of single words. We pass these through an LSTM, which learns word context. So as output we get the same word meanings, which somehow also encapsulate word interactions because they have been through the LSTM. Is this correct??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "# Assuming that the LSTM takes one word at a time and the sizes stay the same through the encoder \n",
    "input_size = 300\n",
    "hidden_size = 300\n",
    "output_size = 300\n",
    "num_layers = 2\n",
    "batch_size = 4\n",
    "learning_rate = 0.0007\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model\n",
    "model = DocumentEncoderLSTM(input_size, hidden_size, num_layers)\n",
    "model.cuda()\n",
    "lossfun = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we're encoding the data we are learning the identity function. This means we use input data x as our target. This is a 3D Tensor, and the go-to loss function CrossEntropyLoss expects a 2D Tensor (usually labels are 1D, for every example, so 2D). Should we flatten our x? On the other hand, as it's not really classes we're predicting, it might be more intuitive to use the MSE or something similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pickled GloVe file. Loading...\n",
      "Done. 2195875 words loaded!\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "data = SquadDataset(squad_file_path, glove_file_path, target='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step[100/21899], Loss: 0.0155\n",
      "Epoch [1/10], Step[200/21899], Loss: 0.0102\n",
      "Epoch [1/10], Step[300/21899], Loss: 0.0054\n",
      "Epoch [1/10], Step[400/21899], Loss: 0.0047\n",
      "Epoch [1/10], Step[500/21899], Loss: 0.0049\n",
      "Epoch [1/10], Step[600/21899], Loss: 0.0033\n",
      "Epoch [1/10], Step[700/21899], Loss: 0.0040\n",
      "Epoch [1/10], Step[800/21899], Loss: 0.0030\n",
      "Epoch [1/10], Step[900/21899], Loss: 0.0036\n",
      "Epoch [1/10], Step[1000/21899], Loss: 0.0032\n",
      "Epoch [1/10], Step[1100/21899], Loss: 0.0039\n",
      "Epoch [1/10], Step[1200/21899], Loss: 0.0033\n",
      "Epoch [1/10], Step[1300/21899], Loss: 0.0029\n",
      "Epoch [1/10], Step[1400/21899], Loss: 0.0037\n",
      "Epoch [1/10], Step[1500/21899], Loss: 0.0036\n",
      "Epoch [1/10], Step[1600/21899], Loss: 0.0032\n",
      "Epoch [1/10], Step[1700/21899], Loss: 0.0035\n",
      "Epoch [1/10], Step[1800/21899], Loss: 0.0036\n",
      "Epoch [1/10], Step[1900/21899], Loss: 0.0040\n",
      "Epoch [1/10], Step[2000/21899], Loss: 0.0029\n",
      "Epoch [1/10], Step[2100/21899], Loss: 0.0028\n",
      "Epoch [1/10], Step[2200/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[2300/21899], Loss: 0.0031\n",
      "Epoch [1/10], Step[2400/21899], Loss: 0.0035\n",
      "Epoch [1/10], Step[2500/21899], Loss: 0.0030\n",
      "Epoch [1/10], Step[2600/21899], Loss: 0.0034\n",
      "Epoch [1/10], Step[2700/21899], Loss: 0.0023\n",
      "Epoch [1/10], Step[2800/21899], Loss: 0.0027\n",
      "Epoch [1/10], Step[2900/21899], Loss: 0.0021\n",
      "Epoch [1/10], Step[3000/21899], Loss: 0.0034\n",
      "Epoch [1/10], Step[3100/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[3200/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[3300/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[3400/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[3500/21899], Loss: 0.0038\n",
      "Epoch [1/10], Step[3600/21899], Loss: 0.0029\n",
      "Epoch [1/10], Step[3700/21899], Loss: 0.0031\n",
      "Epoch [1/10], Step[3800/21899], Loss: 0.0026\n",
      "Epoch [1/10], Step[3900/21899], Loss: 0.0031\n",
      "Epoch [1/10], Step[4000/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[4100/21899], Loss: 0.0018\n",
      "Epoch [1/10], Step[4200/21899], Loss: 0.0031\n",
      "Epoch [1/10], Step[4300/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[4400/21899], Loss: 0.0012\n",
      "Epoch [1/10], Step[4500/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[4600/21899], Loss: 0.0029\n",
      "Epoch [1/10], Step[4700/21899], Loss: 0.0027\n",
      "Epoch [1/10], Step[4800/21899], Loss: 0.0026\n",
      "Epoch [1/10], Step[4900/21899], Loss: 0.0026\n",
      "Epoch [1/10], Step[5000/21899], Loss: 0.0028\n",
      "Epoch [1/10], Step[5100/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[5200/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[5300/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[5400/21899], Loss: 0.0029\n",
      "Epoch [1/10], Step[5500/21899], Loss: 0.0031\n",
      "Epoch [1/10], Step[5600/21899], Loss: 0.0037\n",
      "Epoch [1/10], Step[5700/21899], Loss: 0.0030\n",
      "Epoch [1/10], Step[5800/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[5900/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[6000/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[6100/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[6200/21899], Loss: 0.0030\n",
      "Epoch [1/10], Step[6300/21899], Loss: 0.0034\n",
      "Epoch [1/10], Step[6400/21899], Loss: 0.0033\n",
      "Epoch [1/10], Step[6500/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[6600/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[6700/21899], Loss: 0.0031\n",
      "Epoch [1/10], Step[6800/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[6900/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[7000/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[7100/21899], Loss: 0.0029\n",
      "Epoch [1/10], Step[7200/21899], Loss: 0.0016\n",
      "Epoch [1/10], Step[7300/21899], Loss: 0.0035\n",
      "Epoch [1/10], Step[7400/21899], Loss: 0.0030\n",
      "Epoch [1/10], Step[7500/21899], Loss: 0.0018\n",
      "Epoch [1/10], Step[7600/21899], Loss: 0.0032\n",
      "Epoch [1/10], Step[7700/21899], Loss: 0.0017\n",
      "Epoch [1/10], Step[7800/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[7900/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[8000/21899], Loss: 0.0028\n",
      "Epoch [1/10], Step[8100/21899], Loss: 0.0031\n",
      "Epoch [1/10], Step[8200/21899], Loss: 0.0030\n",
      "Epoch [1/10], Step[8300/21899], Loss: 0.0037\n",
      "Epoch [1/10], Step[8400/21899], Loss: 0.0026\n",
      "Epoch [1/10], Step[8500/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[8600/21899], Loss: 0.0026\n",
      "Epoch [1/10], Step[8700/21899], Loss: 0.0046\n",
      "Epoch [1/10], Step[8800/21899], Loss: 0.0031\n",
      "Epoch [1/10], Step[8900/21899], Loss: 0.0023\n",
      "Epoch [1/10], Step[9000/21899], Loss: 0.0019\n",
      "Epoch [1/10], Step[9100/21899], Loss: 0.0021\n",
      "Epoch [1/10], Step[9200/21899], Loss: 0.0020\n",
      "Epoch [1/10], Step[9300/21899], Loss: 0.0042\n",
      "Epoch [1/10], Step[9400/21899], Loss: 0.0029\n",
      "Epoch [1/10], Step[9500/21899], Loss: 0.0026\n",
      "Epoch [1/10], Step[9600/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[9700/21899], Loss: 0.0018\n",
      "Epoch [1/10], Step[9800/21899], Loss: 0.0030\n",
      "Epoch [1/10], Step[9900/21899], Loss: 0.0038\n",
      "Epoch [1/10], Step[10000/21899], Loss: 0.0023\n",
      "Epoch [1/10], Step[10100/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[10200/21899], Loss: 0.0032\n",
      "Epoch [1/10], Step[10300/21899], Loss: 0.0027\n",
      "Epoch [1/10], Step[10400/21899], Loss: 0.0032\n",
      "Epoch [1/10], Step[10500/21899], Loss: 0.0035\n",
      "Epoch [1/10], Step[10600/21899], Loss: 0.0027\n",
      "Epoch [1/10], Step[10700/21899], Loss: 0.0036\n",
      "Epoch [1/10], Step[10800/21899], Loss: 0.0028\n",
      "Epoch [1/10], Step[10900/21899], Loss: 0.0034\n",
      "Epoch [1/10], Step[11000/21899], Loss: 0.0018\n",
      "Epoch [1/10], Step[11100/21899], Loss: 0.0016\n",
      "Epoch [1/10], Step[11200/21899], Loss: 0.0023\n",
      "Epoch [1/10], Step[11300/21899], Loss: 0.0028\n",
      "Epoch [1/10], Step[11400/21899], Loss: 0.0029\n",
      "Epoch [1/10], Step[11500/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[11600/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[11700/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[11800/21899], Loss: 0.0030\n",
      "Epoch [1/10], Step[11900/21899], Loss: 0.0038\n",
      "Epoch [1/10], Step[12000/21899], Loss: 0.0031\n",
      "Epoch [1/10], Step[12100/21899], Loss: 0.0021\n",
      "Epoch [1/10], Step[12200/21899], Loss: 0.0027\n",
      "Epoch [1/10], Step[12300/21899], Loss: 0.0023\n",
      "Epoch [1/10], Step[12400/21899], Loss: 0.0029\n",
      "Epoch [1/10], Step[12500/21899], Loss: 0.0045\n",
      "Epoch [1/10], Step[12600/21899], Loss: 0.0026\n",
      "Epoch [1/10], Step[12700/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[12800/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[12900/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[13000/21899], Loss: 0.0020\n",
      "Epoch [1/10], Step[13100/21899], Loss: 0.0028\n",
      "Epoch [1/10], Step[13200/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[13300/21899], Loss: 0.0020\n",
      "Epoch [1/10], Step[13400/21899], Loss: 0.0017\n",
      "Epoch [1/10], Step[13500/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[13600/21899], Loss: 0.0023\n",
      "Epoch [1/10], Step[13700/21899], Loss: 0.0021\n",
      "Epoch [1/10], Step[13800/21899], Loss: 0.0026\n",
      "Epoch [1/10], Step[13900/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[14000/21899], Loss: 0.0032\n",
      "Epoch [1/10], Step[14100/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[14200/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[14300/21899], Loss: 0.0026\n",
      "Epoch [1/10], Step[14400/21899], Loss: 0.0030\n",
      "Epoch [1/10], Step[14500/21899], Loss: 0.0030\n",
      "Epoch [1/10], Step[14600/21899], Loss: 0.0026\n",
      "Epoch [1/10], Step[14700/21899], Loss: 0.0027\n",
      "Epoch [1/10], Step[14800/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[14900/21899], Loss: 0.0027\n",
      "Epoch [1/10], Step[15000/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[15100/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[15200/21899], Loss: 0.0030\n",
      "Epoch [1/10], Step[15300/21899], Loss: 0.0031\n",
      "Epoch [1/10], Step[15400/21899], Loss: 0.0018\n",
      "Epoch [1/10], Step[15500/21899], Loss: 0.0033\n",
      "Epoch [1/10], Step[15600/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[15700/21899], Loss: 0.0020\n",
      "Epoch [1/10], Step[15800/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[15900/21899], Loss: 0.0034\n",
      "Epoch [1/10], Step[16000/21899], Loss: 0.0027\n",
      "Epoch [1/10], Step[16100/21899], Loss: 0.0027\n",
      "Epoch [1/10], Step[16200/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[16300/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[16400/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[16500/21899], Loss: 0.0018\n",
      "Epoch [1/10], Step[16600/21899], Loss: 0.0037\n",
      "Epoch [1/10], Step[16700/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[16800/21899], Loss: 0.0027\n",
      "Epoch [1/10], Step[16900/21899], Loss: 0.0029\n",
      "Epoch [1/10], Step[17000/21899], Loss: 0.0021\n",
      "Epoch [1/10], Step[17100/21899], Loss: 0.0027\n",
      "Epoch [1/10], Step[17200/21899], Loss: 0.0027\n",
      "Epoch [1/10], Step[17300/21899], Loss: 0.0029\n",
      "Epoch [1/10], Step[17400/21899], Loss: 0.0058\n",
      "Epoch [1/10], Step[17500/21899], Loss: 0.0034\n",
      "Epoch [1/10], Step[17600/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[17700/21899], Loss: 0.0030\n",
      "Epoch [1/10], Step[17800/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[17900/21899], Loss: 0.0019\n",
      "Epoch [1/10], Step[18000/21899], Loss: 0.0032\n",
      "Epoch [1/10], Step[18100/21899], Loss: 0.0036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step[18200/21899], Loss: 0.0023\n",
      "Epoch [1/10], Step[18300/21899], Loss: 0.0021\n",
      "Epoch [1/10], Step[18400/21899], Loss: 0.0026\n",
      "Epoch [1/10], Step[18500/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[18600/21899], Loss: 0.0023\n",
      "Epoch [1/10], Step[18700/21899], Loss: 0.0031\n",
      "Epoch [1/10], Step[18800/21899], Loss: 0.0029\n",
      "Epoch [1/10], Step[18900/21899], Loss: 0.0040\n",
      "Epoch [1/10], Step[19000/21899], Loss: 0.0041\n",
      "Epoch [1/10], Step[19100/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[19200/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[19300/21899], Loss: 0.0020\n",
      "Epoch [1/10], Step[19400/21899], Loss: 0.0023\n",
      "Epoch [1/10], Step[19500/21899], Loss: 0.0027\n",
      "Epoch [1/10], Step[19600/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[19700/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[19800/21899], Loss: 0.0028\n",
      "Epoch [1/10], Step[19900/21899], Loss: 0.0026\n",
      "Epoch [1/10], Step[20000/21899], Loss: 0.0031\n",
      "Epoch [1/10], Step[20100/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[20200/21899], Loss: 0.0017\n",
      "Epoch [1/10], Step[20300/21899], Loss: 0.0027\n",
      "Epoch [1/10], Step[20400/21899], Loss: 0.0022\n",
      "Epoch [1/10], Step[20500/21899], Loss: 0.0019\n",
      "Epoch [1/10], Step[20600/21899], Loss: 0.0019\n",
      "Epoch [1/10], Step[20700/21899], Loss: 0.0036\n",
      "Epoch [1/10], Step[20800/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[20900/21899], Loss: 0.0031\n",
      "Epoch [1/10], Step[21000/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[21100/21899], Loss: 0.0032\n",
      "Epoch [1/10], Step[21200/21899], Loss: 0.0033\n",
      "Epoch [1/10], Step[21300/21899], Loss: 0.0019\n",
      "Epoch [1/10], Step[21400/21899], Loss: 0.0035\n",
      "Epoch [1/10], Step[21500/21899], Loss: 0.0030\n",
      "Epoch [1/10], Step[21600/21899], Loss: 0.0026\n",
      "Epoch [1/10], Step[21700/21899], Loss: 0.0025\n",
      "Epoch [1/10], Step[21800/21899], Loss: 0.0024\n",
      "Epoch [1/10], Step[21900/21899], Loss: 0.0031\n",
      "Epoch [2/10], Step[100/21899], Loss: 0.0026\n",
      "Epoch [2/10], Step[200/21899], Loss: 0.0025\n",
      "Epoch [2/10], Step[300/21899], Loss: 0.0026\n",
      "Epoch [2/10], Step[400/21899], Loss: 0.0032\n",
      "Epoch [2/10], Step[500/21899], Loss: 0.0038\n",
      "Epoch [2/10], Step[600/21899], Loss: 0.0029\n",
      "Epoch [2/10], Step[700/21899], Loss: 0.0028\n",
      "Epoch [2/10], Step[800/21899], Loss: 0.0032\n",
      "Epoch [2/10], Step[900/21899], Loss: 0.0022\n",
      "Epoch [2/10], Step[1000/21899], Loss: 0.0028\n",
      "Epoch [2/10], Step[1100/21899], Loss: 0.0026\n",
      "Epoch [2/10], Step[1200/21899], Loss: 0.0019\n",
      "Epoch [2/10], Step[1300/21899], Loss: 0.0021\n",
      "Epoch [2/10], Step[1400/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[1500/21899], Loss: 0.0022\n",
      "Epoch [2/10], Step[1600/21899], Loss: 0.0025\n",
      "Epoch [2/10], Step[1700/21899], Loss: 0.0028\n",
      "Epoch [2/10], Step[1800/21899], Loss: 0.0019\n",
      "Epoch [2/10], Step[1900/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[2000/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[2100/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[2200/21899], Loss: 0.0028\n",
      "Epoch [2/10], Step[2300/21899], Loss: 0.0026\n",
      "Epoch [2/10], Step[2400/21899], Loss: 0.0029\n",
      "Epoch [2/10], Step[2500/21899], Loss: 0.0030\n",
      "Epoch [2/10], Step[2600/21899], Loss: 0.0020\n",
      "Epoch [2/10], Step[2700/21899], Loss: 0.0019\n",
      "Epoch [2/10], Step[2800/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[2900/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[3000/21899], Loss: 0.0032\n",
      "Epoch [2/10], Step[3100/21899], Loss: 0.0028\n",
      "Epoch [2/10], Step[3200/21899], Loss: 0.0020\n",
      "Epoch [2/10], Step[3300/21899], Loss: 0.0020\n",
      "Epoch [2/10], Step[3400/21899], Loss: 0.0021\n",
      "Epoch [2/10], Step[3500/21899], Loss: 0.0032\n",
      "Epoch [2/10], Step[3600/21899], Loss: 0.0020\n",
      "Epoch [2/10], Step[3700/21899], Loss: 0.0024\n",
      "Epoch [2/10], Step[3800/21899], Loss: 0.0034\n",
      "Epoch [2/10], Step[3900/21899], Loss: 0.0028\n",
      "Epoch [2/10], Step[4000/21899], Loss: 0.0021\n",
      "Epoch [2/10], Step[4100/21899], Loss: 0.0025\n",
      "Epoch [2/10], Step[4200/21899], Loss: 0.0021\n",
      "Epoch [2/10], Step[4300/21899], Loss: 0.0031\n",
      "Epoch [2/10], Step[4400/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[4500/21899], Loss: 0.0036\n",
      "Epoch [2/10], Step[4600/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[4700/21899], Loss: 0.0029\n",
      "Epoch [2/10], Step[4800/21899], Loss: 0.0028\n",
      "Epoch [2/10], Step[4900/21899], Loss: 0.0042\n",
      "Epoch [2/10], Step[5000/21899], Loss: 0.0029\n",
      "Epoch [2/10], Step[5100/21899], Loss: 0.0019\n",
      "Epoch [2/10], Step[5200/21899], Loss: 0.0022\n",
      "Epoch [2/10], Step[5300/21899], Loss: 0.0038\n",
      "Epoch [2/10], Step[5400/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[5500/21899], Loss: 0.0037\n",
      "Epoch [2/10], Step[5600/21899], Loss: 0.0034\n",
      "Epoch [2/10], Step[5700/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[5800/21899], Loss: 0.0021\n",
      "Epoch [2/10], Step[5900/21899], Loss: 0.0022\n",
      "Epoch [2/10], Step[6000/21899], Loss: 0.0028\n",
      "Epoch [2/10], Step[6100/21899], Loss: 0.0026\n",
      "Epoch [2/10], Step[6200/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[6300/21899], Loss: 0.0028\n",
      "Epoch [2/10], Step[6400/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[6500/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[6600/21899], Loss: 0.0024\n",
      "Epoch [2/10], Step[6700/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[6800/21899], Loss: 0.0021\n",
      "Epoch [2/10], Step[6900/21899], Loss: 0.0035\n",
      "Epoch [2/10], Step[7000/21899], Loss: 0.0039\n",
      "Epoch [2/10], Step[7100/21899], Loss: 0.0029\n",
      "Epoch [2/10], Step[7200/21899], Loss: 0.0020\n",
      "Epoch [2/10], Step[7300/21899], Loss: 0.0020\n",
      "Epoch [2/10], Step[7400/21899], Loss: 0.0021\n",
      "Epoch [2/10], Step[7500/21899], Loss: 0.0029\n",
      "Epoch [2/10], Step[7600/21899], Loss: 0.0032\n",
      "Epoch [2/10], Step[7700/21899], Loss: 0.0025\n",
      "Epoch [2/10], Step[7800/21899], Loss: 0.0020\n",
      "Epoch [2/10], Step[7900/21899], Loss: 0.0032\n",
      "Epoch [2/10], Step[8000/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[8100/21899], Loss: 0.0028\n",
      "Epoch [2/10], Step[8200/21899], Loss: 0.0025\n",
      "Epoch [2/10], Step[8300/21899], Loss: 0.0015\n",
      "Epoch [2/10], Step[8400/21899], Loss: 0.0031\n",
      "Epoch [2/10], Step[8500/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[8600/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[8700/21899], Loss: 0.0020\n",
      "Epoch [2/10], Step[8800/21899], Loss: 0.0026\n",
      "Epoch [2/10], Step[8900/21899], Loss: 0.0025\n",
      "Epoch [2/10], Step[9000/21899], Loss: 0.0024\n",
      "Epoch [2/10], Step[9100/21899], Loss: 0.0019\n",
      "Epoch [2/10], Step[9200/21899], Loss: 0.0028\n",
      "Epoch [2/10], Step[9300/21899], Loss: 0.0030\n",
      "Epoch [2/10], Step[9400/21899], Loss: 0.0015\n",
      "Epoch [2/10], Step[9500/21899], Loss: 0.0031\n",
      "Epoch [2/10], Step[9600/21899], Loss: 0.0037\n",
      "Epoch [2/10], Step[9700/21899], Loss: 0.0021\n",
      "Epoch [2/10], Step[9800/21899], Loss: 0.0018\n",
      "Epoch [2/10], Step[9900/21899], Loss: 0.0022\n",
      "Epoch [2/10], Step[10000/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[10100/21899], Loss: 0.0031\n",
      "Epoch [2/10], Step[10200/21899], Loss: 0.0019\n",
      "Epoch [2/10], Step[10300/21899], Loss: 0.0021\n",
      "Epoch [2/10], Step[10400/21899], Loss: 0.0021\n",
      "Epoch [2/10], Step[10500/21899], Loss: 0.0032\n",
      "Epoch [2/10], Step[10600/21899], Loss: 0.0017\n",
      "Epoch [2/10], Step[10700/21899], Loss: 0.0025\n",
      "Epoch [2/10], Step[10800/21899], Loss: 0.0026\n",
      "Epoch [2/10], Step[10900/21899], Loss: 0.0049\n",
      "Epoch [2/10], Step[11000/21899], Loss: 0.0024\n",
      "Epoch [2/10], Step[11100/21899], Loss: 0.0028\n",
      "Epoch [2/10], Step[11200/21899], Loss: 0.0034\n",
      "Epoch [2/10], Step[11300/21899], Loss: 0.0038\n",
      "Epoch [2/10], Step[11400/21899], Loss: 0.0029\n",
      "Epoch [2/10], Step[11500/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[11600/21899], Loss: 0.0028\n",
      "Epoch [2/10], Step[11700/21899], Loss: 0.0032\n",
      "Epoch [2/10], Step[11800/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[11900/21899], Loss: 0.0018\n",
      "Epoch [2/10], Step[12000/21899], Loss: 0.0024\n",
      "Epoch [2/10], Step[12100/21899], Loss: 0.0017\n",
      "Epoch [2/10], Step[12200/21899], Loss: 0.0025\n",
      "Epoch [2/10], Step[12300/21899], Loss: 0.0031\n",
      "Epoch [2/10], Step[12400/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[12500/21899], Loss: 0.0025\n",
      "Epoch [2/10], Step[12600/21899], Loss: 0.0021\n",
      "Epoch [2/10], Step[12700/21899], Loss: 0.0018\n",
      "Epoch [2/10], Step[12800/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[12900/21899], Loss: 0.0033\n",
      "Epoch [2/10], Step[13000/21899], Loss: 0.0029\n",
      "Epoch [2/10], Step[13100/21899], Loss: 0.0018\n",
      "Epoch [2/10], Step[13200/21899], Loss: 0.0026\n",
      "Epoch [2/10], Step[13300/21899], Loss: 0.0041\n",
      "Epoch [2/10], Step[13400/21899], Loss: 0.0025\n",
      "Epoch [2/10], Step[13500/21899], Loss: 0.0021\n",
      "Epoch [2/10], Step[13600/21899], Loss: 0.0026\n",
      "Epoch [2/10], Step[13700/21899], Loss: 0.0013\n",
      "Epoch [2/10], Step[13800/21899], Loss: 0.0024\n",
      "Epoch [2/10], Step[13900/21899], Loss: 0.0029\n",
      "Epoch [2/10], Step[14000/21899], Loss: 0.0032\n",
      "Epoch [2/10], Step[14100/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[14200/21899], Loss: 0.0020\n",
      "Epoch [2/10], Step[14300/21899], Loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step[14400/21899], Loss: 0.0025\n",
      "Epoch [2/10], Step[14500/21899], Loss: 0.0032\n",
      "Epoch [2/10], Step[14600/21899], Loss: 0.0032\n",
      "Epoch [2/10], Step[14700/21899], Loss: 0.0019\n",
      "Epoch [2/10], Step[14800/21899], Loss: 0.0026\n",
      "Epoch [2/10], Step[14900/21899], Loss: 0.0033\n",
      "Epoch [2/10], Step[15000/21899], Loss: 0.0024\n",
      "Epoch [2/10], Step[15100/21899], Loss: 0.0024\n",
      "Epoch [2/10], Step[15200/21899], Loss: 0.0030\n",
      "Epoch [2/10], Step[15300/21899], Loss: 0.0036\n",
      "Epoch [2/10], Step[15400/21899], Loss: 0.0029\n",
      "Epoch [2/10], Step[15500/21899], Loss: 0.0019\n",
      "Epoch [2/10], Step[15600/21899], Loss: 0.0020\n",
      "Epoch [2/10], Step[15700/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[15800/21899], Loss: 0.0032\n",
      "Epoch [2/10], Step[15900/21899], Loss: 0.0013\n",
      "Epoch [2/10], Step[16000/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[16100/21899], Loss: 0.0025\n",
      "Epoch [2/10], Step[16200/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[16300/21899], Loss: 0.0029\n",
      "Epoch [2/10], Step[16400/21899], Loss: 0.0020\n",
      "Epoch [2/10], Step[16500/21899], Loss: 0.0031\n",
      "Epoch [2/10], Step[16600/21899], Loss: 0.0025\n",
      "Epoch [2/10], Step[16700/21899], Loss: 0.0022\n",
      "Epoch [2/10], Step[16800/21899], Loss: 0.0024\n",
      "Epoch [2/10], Step[16900/21899], Loss: 0.0035\n",
      "Epoch [2/10], Step[17000/21899], Loss: 0.0029\n",
      "Epoch [2/10], Step[17100/21899], Loss: 0.0025\n",
      "Epoch [2/10], Step[17200/21899], Loss: 0.0037\n",
      "Epoch [2/10], Step[17300/21899], Loss: 0.0020\n",
      "Epoch [2/10], Step[17400/21899], Loss: 0.0022\n",
      "Epoch [2/10], Step[17500/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[17600/21899], Loss: 0.0024\n",
      "Epoch [2/10], Step[17700/21899], Loss: 0.0034\n",
      "Epoch [2/10], Step[17800/21899], Loss: 0.0030\n",
      "Epoch [2/10], Step[17900/21899], Loss: 0.0020\n",
      "Epoch [2/10], Step[18000/21899], Loss: 0.0035\n",
      "Epoch [2/10], Step[18100/21899], Loss: 0.0020\n",
      "Epoch [2/10], Step[18200/21899], Loss: 0.0025\n",
      "Epoch [2/10], Step[18300/21899], Loss: 0.0019\n",
      "Epoch [2/10], Step[18400/21899], Loss: 0.0022\n",
      "Epoch [2/10], Step[18500/21899], Loss: 0.0020\n",
      "Epoch [2/10], Step[18600/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[18700/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[18800/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[18900/21899], Loss: 0.0030\n",
      "Epoch [2/10], Step[19000/21899], Loss: 0.0023\n",
      "Epoch [2/10], Step[19100/21899], Loss: 0.0042\n",
      "Epoch [2/10], Step[19200/21899], Loss: 0.0021\n",
      "Epoch [2/10], Step[19300/21899], Loss: 0.0021\n",
      "Epoch [2/10], Step[19400/21899], Loss: 0.0027\n",
      "Epoch [2/10], Step[19500/21899], Loss: 0.0023\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-400d6d438ad6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Repositories\\DCNplus\\src\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'question'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mdata_point\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mdata_point\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_point\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_point\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Repositories\\DCNplus\\src\\preprocessing.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0msequence\u001b[0m \u001b[0mto\u001b[0m \u001b[0mlength\u001b[0m \u001b[1;36m600.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \"\"\"\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mtokenized_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0membedded_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenized_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0membedded_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedded_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Repositories\\DCNplus\\src\\preprocessing.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     90\u001b[0m         annotated_text = self.annotator.annotate(text, \n\u001b[0;32m     91\u001b[0m                                                  properties={'annotators': 'tokenize', \n\u001b[1;32m---> 92\u001b[1;33m                                                               \"outputFormat\": \"json\"})\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[0mtokenized_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mannotated_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tokens'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\site-packages\\pycorenlp\\corenlp.py\u001b[0m in \u001b[0;36mannotate\u001b[1;34m(self, text, properties)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Checks that the Stanford CoreNLP server is started.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             raise Exception('Check whether you have started the CoreNLP server e.g.\\n'\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    506\u001b[0m         }\n\u001b[0;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 )\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;31m# Reset the timeout for the recv() on the socket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m   1105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_content_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m   1150\u001b[0m             \u001b[1;31m# default charset of iso-8859-1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body)\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    875\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 877\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    878\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 141\u001b[1;33m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSocketTimeout\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mfamily\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallowed_gai_family\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0msock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\deep-learning-env\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[1;31m# and socket type values to enum constants.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    734\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m         addrlist.append((_intenum_converter(af, AddressFamily),\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, data_batch in enumerate(dataloader):\n",
    "        x = Variable(data_batch['text'].float())\n",
    "        x = x.cuda()\n",
    "        y = x\n",
    "        \n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = lossfun(output[0], y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1)%100 == 0:\n",
    "            print('Epoch [%d/%d], Step[%d/%d], Loss: %0.4f'\n",
    "                  %(epoch+1, num_epochs, i+1, len(data)//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
